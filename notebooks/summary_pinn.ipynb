{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f765b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import dirname\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "tch_device = torch.device(\"cpu\")\n",
    "tch_dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cc95d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_unique_mask(prtinv, prtcnt):\n",
    "    \"\"\"\n",
    "        Generates mask for unique protein samples\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        prtinv: (torch.tensor) indicates where elements in the original \n",
    "            input ended up in the unique list. This has a shape of `(n_seedsamps,)`.\n",
    "        \n",
    "        prtcnt: (torch.tensor) The count of each unique protein. This has \n",
    "            a shape of `(n_unq,)`.\n",
    "    \n",
    "    \n",
    "        Outputs\n",
    "        -------\n",
    "        mask1d: (torch.tensor) dtype (torch.bool) `(n_seedsamps,)`.\n",
    "        \n",
    "    \"\"\"\n",
    "    n_seedsamps, = prtinv.shape\n",
    "    n_unq, = prtcnt.shape\n",
    "    \n",
    "    # The following is only necessary for creating the \"first occurance boolean mask\".\n",
    "    #prtinvind_sorted = torch.argsort(prtinv, stable=True) # stable is in torch version 1.13.0\n",
    "    pp = prtinv + torch.arange(n_seedsamps, device=prtinv.device)/n_seedsamps # same functionality as stable\n",
    "    prtinvind_sorted = torch.argsort(pp)\n",
    "    assert prtinvind_sorted.shape == (n_seedsamps,)\n",
    "    prtcnt_cs = prtcnt.cumsum(dim=0)\n",
    "    assert prtcnt_cs.shape == (n_unq,)\n",
    "    prtcnt_cszp = torch.cat([prtcnt.new_zeros(1), prtcnt_cs[:-1]])\n",
    "    assert prtcnt_cszp.shape == (n_unq,)\n",
    "    mask_idx = prtinvind_sorted[prtcnt_cszp].sort().values\n",
    "    assert mask_idx.shape == (n_unq,)\n",
    "    mask1d = torch.zeros(n_seedsamps, device=prtinv.device, dtype=torch.bool)\n",
    "    mask1d[mask_idx] = 1\n",
    "    assert mask1d.shape == (n_seedsamps,)\n",
    "#     mask = mask1d.reshape(n_seeds, n_samps)\n",
    "#     assert mask.shape == (n_seeds, n_samps)\n",
    "\n",
    "    return mask1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f84fe",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def BStrap(df, grp_cols, rng_vars, target_vars, n_boot, q_low=0.05, q_high=0.95, tch_rng=None):\n",
    "    n_seeds = None\n",
    "    all_setts, all_seed_y = [], []\n",
    "    \n",
    "    n_trg = len(target_vars)\n",
    "    groups = list(df.groupby(grp_cols))\n",
    "    n_sett = len(groups) \n",
    "    for (setting, df_sett) in groups:    \n",
    "        #####################################\n",
    "        # check the sanity of the subset df #\n",
    "        #####################################\n",
    "        for col in df_sett.columns:\n",
    "            if not(col in rng_vars+target_vars):\n",
    "                assert len(df_sett[col].unique()) == 1\n",
    "\n",
    "        if n_seeds is None:\n",
    "            n_seeds = df_sett.shape[0]\n",
    "        all_setts.append(setting)\n",
    "        seed_y_arr = df_sett[target_vars].values\n",
    "        seed_y_arr = seed_y_arr.astype(np.float32)\n",
    "        assert seed_y_arr.shape == (n_seeds, n_trg)\n",
    "        all_seed_y.append(seed_y_arr)\n",
    "\n",
    "    sett_seed_y = np.stack(all_seed_y, axis=0)\n",
    "    assert sett_seed_y.shape == (n_sett, n_seeds, n_trg)\n",
    "    \n",
    "    \n",
    "    sett_seed_y_tnsr = torch.tensor(sett_seed_y)\n",
    "    assert sett_seed_y_tnsr.shape == (n_sett, n_seeds, n_trg)\n",
    "\n",
    "    #########################\n",
    "    ### bootstrap indices ###\n",
    "    #########################\n",
    "\n",
    "    ind_boot = torch.randint(n_seeds, size=(n_sett, n_boot*n_seeds, 1), generator=tch_rng)\n",
    "    assert ind_boot.shape == (n_sett, n_boot*n_seeds, 1)\n",
    "    sett_seed_y_boot = torch.take_along_dim(sett_seed_y_tnsr, ind_boot, dim=-2)\n",
    "    assert sett_seed_y_boot.shape == (n_sett, n_boot*n_seeds, n_trg)\n",
    "    sett_seed_y_boot = sett_seed_y_boot.reshape(n_sett, n_boot, n_seeds, n_trg)\n",
    "    assert sett_seed_y_boot.shape == (n_sett, n_boot, n_seeds, n_trg)\n",
    "    sett_y_boot = sett_seed_y_boot.mean(dim=-2) # average for each bootstrapped set\n",
    "    assert sett_y_boot.shape == (n_sett, n_boot, n_trg)\n",
    "\n",
    "    # confidence interval and the mean for the bootstrapped stat\n",
    "    sett_y_low = sett_y_boot.quantile(q=q_low, dim=-2).detach().cpu().numpy()\n",
    "    assert sett_y_low.shape == (n_sett, n_trg)\n",
    "    sett_y_high = sett_y_boot.quantile(q=q_high, dim=-2).detach().cpu().numpy()\n",
    "    assert sett_y_high.shape == (n_sett, n_trg)\n",
    "    sett_y_mean = sett_y_boot.mean(dim=-2).detach().cpu().numpy()\n",
    "    assert sett_y_mean.shape == (n_sett, n_trg)\n",
    "\n",
    "    #####################################################\n",
    "    ### dataframe of settings with bootstrapped stats ###\n",
    "    #####################################################\n",
    "\n",
    "    dfs = pd.DataFrame(all_setts, columns = grp_cols)\n",
    "    dfl = pd.DataFrame(sett_y_low, columns = [f\"{var}_low\" for var in target_vars])\n",
    "    dfh = pd.DataFrame(sett_y_high, columns = [f\"{var}_high\" for var in target_vars])\n",
    "    dfm = pd.DataFrame(sett_y_mean, columns = [f\"{var}_mean\" for var in target_vars])\n",
    "\n",
    "    df_bs = pd.concat([dfs, dfl, dfh, dfm], axis=1)\n",
    "    assert df_bs.shape == (n_sett, len(grp_cols) + 3*n_trg)\n",
    "\n",
    "    col_order = grp_cols\n",
    "    for col in target_vars:\n",
    "        col_order += [f'{col}_mean', f'{col}_low', f'{col}_high']\n",
    "    df_bs = df_bs[col_order]\n",
    "    \n",
    "    return df_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5893ebf",
   "metadata": {
    "code_folding": [
     7,
     135
    ]
   },
   "outputs": [],
   "source": [
    "data_types = [\"pinn\"]\n",
    "sep_dict = {'(30, 40)': 0, '(40, 50)': 1, '(50, 60)': 2, '(60, 70)': 3, '(70, 80)': 4}\n",
    "qs = torch.tensor([0.5, 0.7, 0.9, 1.]) # quantile of property to compute\n",
    "res_cfg_dict = defaultdict(list)\n",
    "\n",
    "raw_dpath = \"../summary/pinn/01_raw.tsv\"\n",
    "#!rm {raw_dpath}\n",
    "if not os.path.exists(raw_dpath):\n",
    "    ######################\n",
    "    # pgvae+ experiments #\n",
    "    ######################\n",
    "    mbo_steps = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    for data_type in data_types:\n",
    "        resdir = f\"../results/{data_type}\"\n",
    "        for fname in os.listdir(resdir):\n",
    "            if not fname.endswith(\".pt\"):\n",
    "                continue\n",
    "            print(fname)\n",
    "            res = torch.load(f\"{resdir}/{fname}\")\n",
    "            x_org, y_org = res[\"x\"], res[\"y\"]\n",
    "            step, cfg_it = res[\"step\"], res[\"cfg_it\"]\n",
    "            method_name = res[\"method_name\"]\n",
    "            n_samples_gen = res[\"n_samples_gen\"]\n",
    "            weighted_opt_firststep = res[\"weighted_opt_firststep\"]\n",
    "            orc_spec = res[\"orc_spec\"]\n",
    "            imb_ratio = orc_spec[\"ro\"]\n",
    "            tr_size = orc_spec[\"N\"]\n",
    "            high_perc_range = \"fix\"\n",
    "            distance = orc_spec[\"high_perc_range\"]\n",
    "\n",
    "            for mbo_step in mbo_steps:\n",
    "                ###############################################\n",
    "                # get the samples upto the specified mbo step #\n",
    "                ###############################################\n",
    "                ns, xs, *xd = x_org.shape\n",
    "                mask = step < mbo_step\n",
    "                assert mask.shape == (ns, xs)\n",
    "                assert step.shape == (ns, xs)\n",
    "                mask_re = mask.reshape((ns*xs,))\n",
    "\n",
    "                step_re = step.reshape((ns*xs, ))\n",
    "                step_re = step_re[mask_re]\n",
    "                step_re = step_re.reshape((ns, -1))\n",
    "\n",
    "                # filter x\n",
    "                x_re = x_org.reshape((ns*xs, *xd))\n",
    "                y_re = y_org.reshape((ns*xs,))\n",
    "                x_re, y_re = x_re[mask_re], y_re[mask_re]\n",
    "                x = x_re.reshape((ns, -1, *xd))\n",
    "                y = y_re.reshape((ns, -1))\n",
    "                assert x.shape[1] == step_re.shape[1]\n",
    "\n",
    "                #####################\n",
    "                # get the quantiles #\n",
    "                #####################\n",
    "                ns, xs, *xd = x.shape\n",
    "\n",
    "                #########################\n",
    "                ### Remove duplicates ###\n",
    "                #########################\n",
    "                assert y.shape == (ns, xs)\n",
    "                x_gpu = x.to(\"cuda\")\n",
    "                prtinv, prtcnt = apply_unique(x_gpu, x_gpu.device) #\n",
    "                mask1d = get_unique_mask(prtinv, prtcnt)\n",
    "                assert mask1d.shape == (ns*xs,)\n",
    "                mask1d_re = mask1d.reshape((ns, xs))\n",
    "                assert mask1d_re.shape == (ns, xs)\n",
    "                mask1d_re = mask1d_re.to(\"cpu\")\n",
    "\n",
    "                # real zero values should not get mixed up with zero mask values\n",
    "                y_masked = y.detach().clone()\n",
    "                zero_replace = 123*1e05\n",
    "                y_masked[y_masked == 0] == zero_replace\n",
    "\n",
    "                y_masked = y_masked * mask1d_re\n",
    "                assert y_masked.shape == (ns, xs)\n",
    "                y_masked[y_masked == 0] = float('nan')\n",
    "                # convert zeros back to normal\n",
    "                y_masked[y_masked == zero_replace] = 0\n",
    "\n",
    "\n",
    "                #######################################################\n",
    "                ### get quantiles for all samples upto the mbo step ###\n",
    "                #######################################################\n",
    "\n",
    "                yqs = torch.nanquantile(y_masked, qs, dim=-1)\n",
    "                assert yqs.shape == (qs.numel(), ns)\n",
    "                yqs = yqs.transpose(0, 1)\n",
    "                assert yqs.shape == (ns, qs.numel())\n",
    "                yqs_np = yqs.detach().numpy()\n",
    "\n",
    "                for nss in range(ns):\n",
    "                    # accumulating the stats for different runs\n",
    "                    res_cfg_dict[\"cfg_it\"].append(cfg_it)\n",
    "                    res_cfg_dict[\"data_type\"].append(data_type)\n",
    "                    res_cfg_dict[\"method_name\"].append(method_name)\n",
    "                    res_cfg_dict[\"wopt_fst_step\"].append(weighted_opt_firststep)\n",
    "                    res_cfg_dict[\"mbo_step\"].append(mbo_step)\n",
    "                    res_cfg_dict[\"hrange\"].append(high_perc_range)\n",
    "                    res_cfg_dict[\"distance\"].append(distance)\n",
    "                    res_cfg_dict[\"imb_ratio\"].append(imb_ratio)\n",
    "                    res_cfg_dict[\"n_samples_gen\"].append(n_samples_gen)\n",
    "                    res_cfg_dict[\"tr_size\"].append(tr_size)\n",
    "                    res_cfg_dict[\"fname\"].append(fname)\n",
    "                    res_cfg_dict[\"seed\"].append(nss)\n",
    "\n",
    "                    for qid, q in enumerate(qs):\n",
    "                        res_cfg_dict[f\"y_{int(100*q)}\"].append(yqs_np[nss, qid])\n",
    "    \n",
    "    df_stats = pd.DataFrame.from_dict(res_cfg_dict, orient=\"index\").transpose()\n",
    "    # df_stats: per setting, mbo_step and seed report the target variables (percentiles of property)\n",
    "    df_stats[\"wopt_fst_step\"] = df_stats[\"wopt_fst_step\"].fillna(False)\n",
    "    df_stats[\"wopt_fst_step\"] = df_stats[\"wopt_fst_step\"].apply(lambda x: \"/wopt\" if x else \"\")\n",
    "    df_stats[\"method_name\"] = df_stats[\"method_name\"] + df_stats[\"wopt_fst_step\"]\n",
    "    \n",
    "    ####################################\n",
    "    ### Compute relative performance ###\n",
    "    ####################################\n",
    "    \n",
    "    sett_vars = [\"data_type\", \"method_name\", \"wopt_fst_step\", \"hrange\", \"distance\", \"imb_ratio\", \"n_samples_gen\", \"seed\"]\n",
    "    groups = list(df_stats.groupby(sett_vars))\n",
    "    target_vars = [f\"y_{int(100*q)}\" for q in qs]\n",
    "\n",
    "    df_lst = []\n",
    "    for i, (grp_sett, df_grp) in enumerate(groups):\n",
    "        assert len(df_grp[\"mbo_step\"]) == len(df_grp[\"mbo_step\"].unique())\n",
    "        df_grp2 = df_grp.copy(deep=True)\n",
    "        for target_var in target_vars:\n",
    "            y0 = df_grp[df_grp[\"mbo_step\"] == 0][target_var].values.item()\n",
    "            df_grp2[f\"d{target_var}\"] = df_grp2[target_var] - y0\n",
    "        df_lst.append(df_grp2)\n",
    "    df_stats = pd.concat(df_lst, axis=0, ignore_index=True)\n",
    "    \n",
    "    os.makedirs(dirname(raw_dpath), exist_ok=True)\n",
    "    df_stats.to_csv(raw_dpath, sep=\"\\t\", index=False)\n",
    "else:\n",
    "    print(\"loading stats from file\")\n",
    "    df_stats = pd.read_csv(raw_dpath, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179d25f",
   "metadata": {
    "code_folding": [
     6,
     29
    ]
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "### Compute the confidence interval via bootstrapping ###\n",
    "#########################################################\n",
    "\n",
    "bts_dpath = \"../summary/pinn/02_bts.prq\"\n",
    "# !rm {bts_dpath}\n",
    "if not os.path.exists(bts_dpath):\n",
    "    # set of variables identifying a setting\n",
    "    sett_vars = [\"data_type\", \"method_name\", \"wopt_fst_step\", \"imb_ratio\", \"hrange\", \"distance\", \"n_samples_gen\"]\n",
    "    # target variables to compute the confidence interval for\n",
    "    target_vars = [f\"y_{int(100*q)}\" for q in qs] + [f\"dy_{int(100*q)}\" for q in qs]\n",
    "    rng_vars = [\"seed\"]\n",
    "    step_vars = [\"mbo_step\"]\n",
    "\n",
    "    ### bootstap settings ###\n",
    "    n_boot = 1000\n",
    "    q_low, q_high = 0.05, 0.95\n",
    "    grp_cols = sett_vars + step_vars\n",
    "\n",
    "    tch_seed = 1234567891011\n",
    "    tch_rng = torch.Generator(device=tch_device)\n",
    "    tch_rng.manual_seed(tch_seed)\n",
    "\n",
    "    df_bs = BStrap(df_stats, grp_cols, rng_vars, target_vars, n_boot, q_low=0.05, q_high=0.95, tch_rng=tch_rng)\n",
    "    # define the separation level\n",
    "    df_bs[\"sep_level\"] = df_bs[\"distance\"].apply(lambda x: sep_dict[x])\n",
    "\n",
    "    os.makedirs(dirname(bts_dpath), exist_ok=True)\n",
    "    df_bs.to_parquet(bts_dpath)\n",
    "else:\n",
    "    print(\"loading form file\")\n",
    "    df_bs = pd.read_parquet(bts_dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4c31a",
   "metadata": {
    "code_folding": [
     7,
     31
    ]
   },
   "outputs": [],
   "source": [
    "######### Bootstrapping for imb ratios combined #########\n",
    "#########################################################\n",
    "### Compute the confidence interval via bootstrapping ###\n",
    "#########################################################\n",
    "\n",
    "btsg_dpath = \"../summary/pinn/03_btsg.prq\"\n",
    "# !rm {btsg_dpath}\n",
    "if not os.path.exists(btsg_dpath):\n",
    "    # set of variables identifying a setting\n",
    "    sett_vars = [\"data_type\", \"method_name\", \"wopt_fst_step\", \"hrange\", \"distance\", \"n_samples_gen\"]\n",
    "    # target variables to compute the confidence interval for\n",
    "    target_vars = [f\"y_{int(100*q)}\" for q in qs] + [f\"dy_{int(100*q)}\" for q in qs]\n",
    "    rng_vars = [\"seed\", \"imb_ratio\"]\n",
    "    step_vars = [\"mbo_step\"]\n",
    "\n",
    "    ### bootstap settings ###\n",
    "    n_boot = 1000\n",
    "    q_low, q_high = 0.05, 0.95\n",
    "    grp_cols = sett_vars + step_vars\n",
    "\n",
    "    tch_seed = 1234567891011\n",
    "    tch_rng = torch.Generator(device=tch_device)\n",
    "    tch_rng.manual_seed(tch_seed)\n",
    "\n",
    "    # exclude these columns because it changes from one setting to another (imb_ratio is included in seeds)\n",
    "    df_stats_ = df_stats.drop([\"cfg_it\", \"fname\", \"tr_size\"], axis=1)\n",
    "    df_bsg = BStrap(df_stats_, grp_cols, rng_vars, target_vars, n_boot, q_low=0.05, q_high=0.95, tch_rng=tch_rng)\n",
    "    df_bsg[\"sep_level\"] = df_bsg[\"distance\"].apply(lambda x: sep_dict[x])\n",
    "    \n",
    "    os.makedirs(dirname(btsg_dpath), exist_ok=True)\n",
    "    df_bsg.to_parquet(btsg_dpath)\n",
    "else:\n",
    "    print(\"loading form file\")\n",
    "    df_bsg = pd.read_parquet(btsg_dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538fa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opence172",
   "language": "python",
   "name": "opence172"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
