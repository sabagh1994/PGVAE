{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21bc19f6",
   "metadata": {},
   "source": [
    "## Train set and Oracle generation\n",
    "\n",
    "For each benchmark task, generate train sets at varying imbalance ratios and separation levels. Also generate the oracles. \\\n",
    "Note that for pinn the oracle is read from the file and for gmm\n",
    "the oracle is constructed from its parameters saved with the train set. \\\n",
    "For semi-synthetic protein datasets, the oracles are created for different lengths of appended sequencs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed_rng = 12345\n",
    "torch.manual_seed(seed_rng)\n",
    "np.random.seed(seed_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22387c",
   "metadata": {
    "code_folding": [
     2,
     7,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# taken from ECNet code: https://github.com/luoyunan/ECNet\n",
    "from Bio import SeqIO\n",
    "def _read_native_sequence(data_dir):\n",
    "    fasta = SeqIO.read(f'{data_dir}/native_sequence.fasta', 'fasta')\n",
    "    native_sequence = str(fasta.seq)\n",
    "    return native_sequence\n",
    "\n",
    "def _mutation_to_sequence(mutation, native_sequence):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    mutation: ';'.join(WiM) (wide-type W at position i mutated to M)\n",
    "    '''\n",
    "    sequence = native_sequence\n",
    "    mut_positions = []\n",
    "    \n",
    "    splitter = \";\" if (\";\" in mutation) else \":\"\n",
    "    for mut in mutation.split(splitter):\n",
    "        wt_aa = mut[0]\n",
    "        mt_aa = mut[-1]\n",
    "        pos = int(mut[1:-1])\n",
    "        assert wt_aa == sequence[pos - 1],\\\n",
    "                \"%s: %s->%s (fasta WT: %s)\"%(pos, wt_aa, mt_aa, sequence[pos - 1])\n",
    "        sequence = sequence[:(pos - 1)] + mt_aa + sequence[pos:]\n",
    "        mut_positions.append(str(pos - 1))\n",
    "    mut_positions = \",\".join(mut_positions)\n",
    "    return sequence, mut_positions\n",
    "\n",
    "def _drop_invalid_mutation(df, native_sequence):\n",
    "    '''\n",
    "    Drop mutations WiM where\n",
    "    - W is incosistent with the i-th AA in native_sequence\n",
    "    - M is ambiguous, e.g., 'X'\n",
    "    '''\n",
    "    flags = []\n",
    "    for mutation in df['mutation'].values:\n",
    "        splitter = \";\" if (\";\" in mutation) else \":\"\n",
    "        for mut in mutation.split(splitter):\n",
    "            wt_aa = mut[0]\n",
    "            mt_aa = mut[-1]\n",
    "            pos = int(mut[1:-1])\n",
    "            valid = True if wt_aa == native_sequence[pos - 1] else False\n",
    "            valid = valid and (mt_aa not in ['X'])\n",
    "        flags.append(valid)\n",
    "    df = df[flags].reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d747a",
   "metadata": {},
   "source": [
    "### Protein GB1_syth: \n",
    "The length of the appended sequence controls the separation level. \\\n",
    "The length is controlled by varianle `ext_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a2a47",
   "metadata": {
    "code_folding": [
     1,
     90
    ]
   },
   "outputs": [],
   "source": [
    "ext_lens = [3, 4, 5, 8]\n",
    "for ext_len in ext_lens:\n",
    "    seed_rng = 12345\n",
    "    np.random.seed(seed_rng)\n",
    "\n",
    "    data_type = \"protein\"\n",
    "    ds_name = f\"protein_gb_synth_l{ext_len}\"\n",
    "    savedir = f\"../sample_trainset/{ds_name}\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "\n",
    "    ########################\n",
    "    ### Build the Oracle ###\n",
    "    ########################\n",
    "\n",
    "    oracle_dir = \"../oracles\"\n",
    "    os.makedirs(oracle_dir, exist_ok=True)\n",
    "    orc_dir = \"../datasets/GB1.txt\"\n",
    "    df_orc = pd.read_csv(orc_dir, sep=\"\\t\")\n",
    "    df_orc = df_orc[[\"Variants\", \"Fitness\"]]\n",
    "    df_orc.columns = [\"sequence\", \"score\"]\n",
    "    df_orc[\"score\"] = df_orc[\"score\"]/max(df_orc[\"score\"])\n",
    "    scores_gt = df_orc[\"score\"]\n",
    "\n",
    "    ###########################\n",
    "    ##### concat the seqs #####\n",
    "    ###########################\n",
    "\n",
    "    split_thr = 0.001 # 0.01\n",
    "    df_orc_low = df_orc.loc[df_orc[\"score\"] < split_thr]\n",
    "    df_orc_high = df_orc.loc[df_orc[\"score\"] >= split_thr]\n",
    "\n",
    "    CCMPRED_AMINO_ACID_INDEX = collections.OrderedDict(\n",
    "        {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4,\n",
    "         'Q': 5, 'E': 6, 'G': 7, 'H': 8, 'I': 9,\n",
    "         'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14,\n",
    "         'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19, '-': 20})\n",
    "\n",
    "    #####################################\n",
    "    aas = list(CCMPRED_AMINO_ACID_INDEX.keys())[:-1] # excluding '-'\n",
    "    nmax = len(aas)\n",
    "    slow = df_orc_low.shape[0]\n",
    "\n",
    "    inds = np.random.randint(nmax, size=slow*(ext_len-1))\n",
    "    inds_end = np.random.randint(nmax-1, size=slow) # ecxlude the last aa for the last position\n",
    "    aas_arr = np.array(aas)\n",
    "\n",
    "    seq_ext = aas_arr[inds]\n",
    "    seq_ext_end = aas_arr[inds_end]\n",
    "    assert seq_ext.shape == (slow*(ext_len-1),)\n",
    "    assert seq_ext_end.shape == (slow,)\n",
    "    seq_ext_arr = seq_ext.reshape(slow, (ext_len-1))\n",
    "    seq_ext_arr_end = seq_ext_end.reshape(slow, 1)\n",
    "    seq_ext_arr = np.concatenate((seq_ext_arr, seq_ext_arr_end), axis=-1)\n",
    "    assert seq_ext_arr.shape == (slow, ext_len)\n",
    "\n",
    "    seq_ext_low = [\"\".join(list(seqext)) for seqext in seq_ext_arr]\n",
    "    df_orc_low[\"ext\"] = seq_ext_low\n",
    "    df_orc_low[\"sequence\"] = df_orc_low[\"ext\"] + df_orc_low[\"sequence\"]\n",
    "    df_orc_low = df_orc_low[[\"sequence\", \"score\"]]\n",
    "\n",
    "    #####################################\n",
    "\n",
    "    # generate the extension for the high end\n",
    "    inds = np.random.randint(nmax, size=ext_len)\n",
    "    seq_ext_high = list(aas_arr[inds])\n",
    "    seq_ext_high = \"\".join(seq_ext_high)\n",
    "    seq_ext_high = seq_ext_high[:-1] + aas[-1]\n",
    "    print(seq_ext_high)\n",
    "    df_orc_high[\"sequence\"] = seq_ext_high + df_orc_high[\"sequence\"]\n",
    "    df_orc = pd.concat((df_orc_low, df_orc_high))\n",
    "\n",
    "\n",
    "    # save the oracle\n",
    "    orc_savedir = f\"{oracle_dir}/{ds_name}\"\n",
    "    df_orc.to_csv(orc_savedir, sep= \"\\t\", index=False)\n",
    "    \n",
    "    #######################################################\n",
    "    # train set generation for different imbalance ratios #\n",
    "    #######################################################\n",
    "    \n",
    "    ros = [0.0125, 0.025, 0.05, 0.1, 0.2, 0.4, 0.8]\n",
    "    Ntrs = [1000]\n",
    "    high_end_ranges = [(0.1, 0.2)]\n",
    "    low_end_ranges = [(0.0001, 0.001)]\n",
    "\n",
    "    cfg_lists = [ros, Ntrs, high_end_ranges, low_end_ranges]\n",
    "    cfgs = itertools.product(*cfg_lists)\n",
    "\n",
    "    orc_specs = defaultdict(list)\n",
    "    for cfg_it, cfg in enumerate(cfgs):\n",
    "        ro, Ntr, high_end_range, low_end_range = cfg\n",
    "        low_perc = 10\n",
    "        print(f\"cfg is {cfg}\")\n",
    "\n",
    "        h1_end, h2_end = high_end_range\n",
    "        l1_end, l2_end = low_end_range\n",
    "        trs_low = Ntr\n",
    "        trs_high = int(Ntr * ro)\n",
    "\n",
    "        idx_low = np.where((l1_end <= df_orc[\"score\"]) & (df_orc[\"score\"] < l2_end))[0]\n",
    "        rand_idx_low = np.random.choice(idx_low, size=trs_low, replace=False)\n",
    "\n",
    "        idx_high = np.where((h1_end <= df_orc[\"score\"]) & (df_orc[\"score\"] <= h2_end))[0]\n",
    "        rand_idx_high = np.random.choice(idx_high, size=trs_high, replace=False)\n",
    "\n",
    "        df_orc_low = df_orc.iloc[rand_idx_low, :]\n",
    "        df_orc_high = df_orc.iloc[rand_idx_high, :]\n",
    "        df = pd.concat((df_orc_low, df_orc_high))\n",
    "        #print(df_orc_low.shape[0], df_orc_high.shape[0])\n",
    "\n",
    "        orc_spec = dict(cfg_it=cfg_it, ro=ro, high_end_range=high_end_range,\n",
    "                        low_end_range=low_end_range, data_type=data_type, \n",
    "                        N=int(Ntr*(1+ro)), orc_path=orc_savedir)\n",
    "\n",
    "        x_tr = df[\"sequence\"].values\n",
    "        y_tr = df[\"score\"].values\n",
    "        np.savez(f\"{savedir}/ds{cfg_it}\", x=x_tr, y=y_tr, orc_spec=orc_spec)\n",
    "\n",
    "        # to get all confings in one file\n",
    "        orc_specs[\"cfg_it\"].append(cfg_it)\n",
    "        orc_specs[\"ro\"].append(ro)\n",
    "        orc_specs[\"high_end_range\"].append(high_end_range)\n",
    "        orc_specs[\"data_type\"].append(data_type)\n",
    "        orc_specs[\"low_end_range\"].append(low_end_range)\n",
    "        orc_specs[\"N\"].append(int(Ntr*(1+ro)))\n",
    "\n",
    "        cfg_all = pd.DataFrame.from_dict(orc_specs, orient='index').transpose()\n",
    "        cfg_all.columns = [\"cfg_it\", \"ro\", \"high_end_range\", \"data_type\", \"low_end_range\", \"N\"]\n",
    "        cfg_all.to_csv(f\"{savedir}/cfgs\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722660c",
   "metadata": {},
   "source": [
    "### Protein PhoQ_syth:\n",
    "The length of the appended sequence controls the separation level. \\\n",
    "The length is controlled by varianle `ext_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524b24e",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "ext_lens = [3, 4, 6, 8]\n",
    "for ext_len in ext_lens:\n",
    "    seed_rng = 12345\n",
    "    np.random.seed(seed_rng)\n",
    "\n",
    "    data_type = \"protein\"\n",
    "    ds_name = f\"protein_phoq_synth_l{ext_len}\"\n",
    "    savedir = f\"../sample_trainset/{ds_name}\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "\n",
    "    ########################\n",
    "    ### Build the Oracle ###\n",
    "    ########################\n",
    "\n",
    "    oracle_dir = \"../oracles/\"\n",
    "    os.makedirs(oracle_dir, exist_ok=True)\n",
    "    orc_dir = \"../datasets/PhoQ.txt\"\n",
    "    df_orc = pd.read_csv(orc_dir, sep=\"\\t\")\n",
    "    df_orc = df_orc[[\"Variants\", \"Fitness\"]]\n",
    "    df_orc.columns = [\"sequence\", \"score\"]\n",
    "    df_orc[\"score\"] = df_orc[\"score\"]/max(df_orc[\"score\"])\n",
    "    scores_gt = df_orc[\"score\"]\n",
    "\n",
    "    ###########################\n",
    "    ##### concat the seqs #####\n",
    "    ###########################\n",
    "\n",
    "    split_thr = 0.001 # 0.01\n",
    "    df_orc_low = df_orc.loc[df_orc[\"score\"] < split_thr]\n",
    "    df_orc_high = df_orc.loc[df_orc[\"score\"] >= split_thr]\n",
    "\n",
    "    CCMPRED_AMINO_ACID_INDEX = collections.OrderedDict(\n",
    "        {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4,\n",
    "         'Q': 5, 'E': 6, 'G': 7, 'H': 8, 'I': 9,\n",
    "         'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14,\n",
    "         'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19, '-': 20})\n",
    "\n",
    "\n",
    "    #############################\n",
    "\n",
    "    aas = list(CCMPRED_AMINO_ACID_INDEX.keys())[:-1] # excluding '-'\n",
    "    nmax = len(aas)\n",
    "    slow = df_orc_low.shape[0]\n",
    "\n",
    "    inds = np.random.randint(nmax, size=slow*(ext_len-1))\n",
    "    inds_end = np.random.randint(nmax-1, size=slow) # ecxlude the last aa for the last position\n",
    "    aas_arr = np.array(aas)\n",
    "\n",
    "    seq_ext = aas_arr[inds]\n",
    "    seq_ext_end = aas_arr[inds_end]\n",
    "    assert seq_ext.shape == (slow*(ext_len-1),)\n",
    "    assert seq_ext_end.shape == (slow,)\n",
    "    seq_ext_arr = seq_ext.reshape(slow, (ext_len-1))\n",
    "    seq_ext_arr_end = seq_ext_end.reshape(slow, 1)\n",
    "    seq_ext_arr = np.concatenate((seq_ext_arr, seq_ext_arr_end), axis=-1)\n",
    "    assert seq_ext_arr.shape == (slow, ext_len)\n",
    "\n",
    "    seq_ext_low = [\"\".join(list(seqext)) for seqext in seq_ext_arr]\n",
    "    df_orc_low[\"ext\"] = seq_ext_low\n",
    "    df_orc_low[\"sequence\"] = df_orc_low[\"ext\"] + df_orc_low[\"sequence\"]\n",
    "    df_orc_low = df_orc_low[[\"sequence\", \"score\"]]\n",
    "    #############################\n",
    "\n",
    "    # generate the extension for the high end\n",
    "    inds = np.random.randint(nmax, size=ext_len)\n",
    "    seq_ext_high = list(aas_arr[inds])\n",
    "    seq_ext_high = \"\".join(seq_ext_high)\n",
    "    seq_ext_high = seq_ext_high[:-1] + aas[-1]\n",
    "    print(seq_ext_high)\n",
    "    df_orc_high[\"sequence\"] = seq_ext_high + df_orc_high[\"sequence\"]\n",
    "    df_orc = pd.concat((df_orc_low, df_orc_high))\n",
    "\n",
    "\n",
    "    # save the oracle\n",
    "    orc_savedir = f\"{oracle_dir}/{ds_name}\"\n",
    "    df_orc.to_csv(orc_savedir, sep= \"\\t\", index=False)\n",
    "    \n",
    "    #######################################################\n",
    "    # train set generation for different imbalance ratios #\n",
    "    #######################################################\n",
    "    \n",
    "    ros = [0.0125, 0.025, 0.05, 0.1, 0.2, 0.4, 0.8]\n",
    "    Ntrs = [1000]\n",
    "    high_end_ranges = [(0.1, 0.2)]\n",
    "    low_end_ranges = [(0.0001, 0.001)]\n",
    "\n",
    "    cfg_lists = [ros, Ntrs, high_end_ranges, low_end_ranges]\n",
    "    cfgs = itertools.product(*cfg_lists)\n",
    "\n",
    "    orc_specs = defaultdict(list)\n",
    "    for cfg_it, cfg in enumerate(cfgs):\n",
    "        ro, Ntr, high_end_range, low_end_range = cfg\n",
    "        print(f\"cfg is {cfg}\")\n",
    "\n",
    "        h1_end, h2_end = high_end_range\n",
    "        l1_end, l2_end = low_end_range\n",
    "        trs_low = Ntr\n",
    "        trs_high = int(Ntr * ro)\n",
    "\n",
    "        idx_low = np.where((l1_end <= df_orc[\"score\"]) & (df_orc[\"score\"] < l2_end))[0]\n",
    "        rand_idx_low = np.random.choice(idx_low, size=trs_low, replace=False)\n",
    "\n",
    "        idx_high = np.where((h1_end <= df_orc[\"score\"]) & (df_orc[\"score\"] <= h2_end))[0]\n",
    "        rand_idx_high = np.random.choice(idx_high, size=trs_high, replace=False)\n",
    "\n",
    "        df_orc_low = df_orc.iloc[rand_idx_low, :]\n",
    "        df_orc_high = df_orc.iloc[rand_idx_high, :]\n",
    "        df = pd.concat((df_orc_low, df_orc_high))\n",
    "\n",
    "        #print(df_orc_low.shape[0], df_orc_high.shape[0])\n",
    "\n",
    "        orc_spec = dict(cfg_it=cfg_it, ro=ro, high_end_range=high_end_range,\n",
    "                        low_end_range=low_end_range, data_type=data_type, \n",
    "                        N=int(Ntr*(1+ro)), orc_path=orc_savedir)\n",
    "\n",
    "        x_tr = df[\"sequence\"].values\n",
    "        y_tr = df[\"score\"].values\n",
    "        np.savez(f\"{savedir}/ds{cfg_it}\", x=x_tr, y=y_tr, orc_spec=orc_spec)\n",
    "\n",
    "        # to get all confings in one file\n",
    "        orc_specs[\"cfg_it\"].append(cfg_it)\n",
    "        orc_specs[\"ro\"].append(ro)\n",
    "        orc_specs[\"high_end_range\"].append(high_end_range)\n",
    "        orc_specs[\"data_type\"].append(data_type)\n",
    "        orc_specs[\"low_end_range\"].append(low_end_range)\n",
    "        orc_specs[\"N\"].append(int(Ntr*(1+ro)))\n",
    "\n",
    "        cfg_all = pd.DataFrame.from_dict(orc_specs, orient='index').transpose()\n",
    "        cfg_all.columns = [\"cfg_it\", \"ro\", \"high_end_range\", \"data_type\", \"low_end_range\", \"N\"]\n",
    "        cfg_all.to_csv(f\"{savedir}/cfgs\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b6dfc",
   "metadata": {},
   "source": [
    "### Protein AAV Virus:\n",
    "paper ref: https://www.nature.com/articles/s41587-020-00793-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f67c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = 12345\n",
    "np.random.seed(rng_seed)\n",
    "\n",
    "data_type = \"protein\"\n",
    "ds_name = \"protein_aav\"\n",
    "savedir = f\"../sample_trainset/{ds_name}\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "########################\n",
    "### Build the Oracle ###\n",
    "########################\n",
    "\n",
    "oracle_dir = \"../oracles/\"\n",
    "os.makedirs(oracle_dir, exist_ok=True)\n",
    "# data downloaded from the FLIP paper \n",
    "# https://github.com/J-SNACKKB/FLIP/tree/main/splits/aav\n",
    "# https://www.biorxiv.org/content/10.1101/2021.11.09.467890v2.full.pdf\n",
    "orc_dir = \"../datasets/aav.csv\"\n",
    "df_aav = pd.read_csv(orc_dir, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aav = df_aav.dropna(subset=[\"number_of_mutations\", \"score\", \"full_aa_sequence\", \"mutation_mask\"])\n",
    "df_aav[\"full_len\"] = df_aav[\"full_aa_sequence\"].apply(lambda x: len(x))\n",
    "df_aav[\"mut_len\"] = df_aav[\"mutated_region\"].apply(lambda x: len(x))\n",
    "ref_len = len(df_aav[\"reference_region\"].values[0])\n",
    "# subset to the mutations that do not change the length\n",
    "df_aav = df_aav[df_aav[\"mut_len\"] == ref_len]\n",
    "assert np.all(df_aav[\"number_of_mutations\"].values < 29)\n",
    "# exclude mutated regions containing *\n",
    "df_aav = df_aav[~df_aav[\"mutated_region\"].str.contains(\"\\*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the oracle which contains both designed and sampled mutants\n",
    "df_orc = df_aav[[\"mutated_region\", \"score\", \"number_of_mutations\", \"mut_des_split\"]] \n",
    "df_orc.columns = [\"sequence\", \"score\", \"number_of_mutations\", \"mut_des_split\"]\n",
    "# transform the score\n",
    "min_, max_ = min(df_orc[\"score\"]), max(df_orc[\"score\"])\n",
    "df_orc[\"score\"] = (df_orc[\"score\"] - min_)/(max_ - min_)\n",
    "\n",
    "# save the oracle\n",
    "orc_savedir = f\"{oracle_dir}/{ds_name}\"\n",
    "df_orc_ = df_orc[[\"sequence\", \"score\"]].reset_index(drop=True)\n",
    "df_orc_.to_csv(orc_savedir, sep= \"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d327e",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # check the properties of the data\n",
    "    df_ = df_orc[df_orc[\"mut_des_split\"] == \"train\"] # mut: sampled (train), des: designed (test)\n",
    "    fig, ax = plt.subplots()\n",
    "    hh = ax.hist2d(x=df_[\"score\"], y=df_[\"number_of_mutations\"], bins=10)\n",
    "    fig.colorbar(hh[3], ax=ax)\n",
    "\n",
    "    df_pos = df_[df_[\"score\"] > -min_/(max_ - min_)] # zero is df_aav is transformed to -min_/(max_ - min_) in df_orc\n",
    "    df_neg = df_[df_[\"score\"] <= -min_/(max_ - min_)]\n",
    "    ctr = df_pos[[\"number_of_mutations\"]].values\n",
    "    plt.figure()\n",
    "    plt.hist(ctr)\n",
    "    plt.title(\"score > 0\")\n",
    "\n",
    "    ctr = df_neg[[\"number_of_mutations\"]].values\n",
    "    plt.figure()\n",
    "    plt.hist(ctr)\n",
    "    plt.title(\"score < 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dceba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_orc[df_orc[\"mut_des_split\"] == \"train\"] # mut: sampled (train), des: designed (test)\n",
    "df_pos = df_[df_[\"score\"] > -min_/(max_ - min_)] # zero in df_aav is transformed to -min_/(max_ - min_) in df_orc\n",
    "df_neg = df_[df_[\"score\"] <= -min_/(max_ - min_)]\n",
    "\n",
    "Ntrs = [1000]\n",
    "ros = [0.0125, 0.025, 0.05, 0.1, 0.2, 0.4, 0.8]\n",
    "high_end_percs = [(5, 10)]\n",
    "mut_thrs = [10, 8, 6]\n",
    "cfg_lists = [ros, Ntrs, high_end_percs, mut_thrs]\n",
    "cfgs = list(itertools.product(*cfg_lists))\n",
    "\n",
    "cfg_lists_add = [ros, Ntrs, high_end_percs, [15, 12]]\n",
    "cfgs_add = list(itertools.product(*cfg_lists_add))\n",
    "\n",
    "cfgs = cfgs + cfgs_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e5eb38",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "orc_specs = defaultdict(list)\n",
    "for cfg_it, cfg in enumerate(cfgs):\n",
    "    ro, Ntr, high_end_perc, mut_thr = cfg\n",
    "    print(f\"cfg is {cfg}\")\n",
    "    tr_high = int(Ntr*ro)\n",
    "\n",
    "    df_neg_tmp = df_neg[df_neg[\"number_of_mutations\"] > mut_thr]\n",
    "    #print(f\"neg score size {df_neg_tmp.shape}, pos score size {df_pos.shape}\")\n",
    "    score_pos = df_pos[\"score\"]\n",
    "\n",
    "    h1_perc, h2_perc = high_end_perc\n",
    "    h1_score, h2_score = np.percentile(score_pos, h1_perc), np.percentile(score_pos, h2_perc)\n",
    "    idx_high = np.where((df_pos.score >= h1_score) & (df_pos.score < h2_score))[0]\n",
    "    #print(f\"idx_high size {idx_high.size}\")\n",
    "\n",
    "    # take sample from the high/pos section\n",
    "    rand_idx_high = np.random.choice(idx_high, size=tr_high, replace=False)\n",
    "    df_pos_samp = df_pos.iloc[rand_idx_high, :]\n",
    "\n",
    "    # take sample from the low/neg region\n",
    "    rand_idx_low = np.random.choice(np.arange(df_neg_tmp.shape[0]), size=Ntr, replace=False)\n",
    "    df_neg_samp = df_neg_tmp.iloc[rand_idx_low, :]\n",
    "\n",
    "    df_all = pd.concat((df_pos_samp, df_neg_samp), axis=0).reset_index(drop=True)\n",
    "    x_tr = df_all[\"sequence\"].values\n",
    "    y_tr = df_all[\"score\"].values\n",
    "\n",
    "    orc_spec = dict(cfg_it=cfg_it, ro=ro, high_end_perc=high_end_perc,\n",
    "                    mut_thr=mut_thr, data_type=data_type, \n",
    "                    N=int(Ntr*(1+ro)), orc_path=orc_savedir)\n",
    "    np.savez(f\"{savedir}/ds{cfg_it}\", x=x_tr, y=y_tr, orc_spec=orc_spec)\n",
    "    \n",
    "    # to get all confings in one file\n",
    "    orc_specs[\"cfg_it\"].append(cfg_it)\n",
    "    orc_specs[\"ro\"].append(ro)\n",
    "    orc_specs[\"high_end_perc\"].append(high_end_perc)\n",
    "    orc_specs[\"data_type\"].append(data_type)\n",
    "    orc_specs[\"mut_thr\"].append(mut_thr)\n",
    "    orc_specs[\"N\"].append(int(Ntr*(1+ro)))\n",
    "    \n",
    "    cfg_all = pd.DataFrame.from_dict(orc_specs, orient='index').transpose()\n",
    "    cfg_all.columns = [\"cfg_it\", \"ro\", \"high_end_perc\", \"data_type\", \"mut_thr\", \"N\"]\n",
    "    cfg_all.to_csv(f\"{savedir}/cfgs\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b5c96",
   "metadata": {},
   "source": [
    "### GMM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2209d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# gmm oracle\n",
    "def oracle_gmm(x, mus, sigmas, weights):\n",
    "    (n_seeds, xs, *xd) = x.shape\n",
    "    n_gmm = mus.shape[0]\n",
    "    assert mus.shape == (n_gmm, *xd)\n",
    "    assert sigmas.shape == (n_gmm, *xd)\n",
    "    assert weights.shape == (n_gmm,)\n",
    "\n",
    "    # for all mus and xs compute x-mu\n",
    "    x = x.reshape((n_seeds, xs, 1, *xd))\n",
    "    mus = mus.reshape((1, 1, n_gmm,  *xd))\n",
    "    sigmas = sigmas.reshape((1, 1, n_gmm,  *xd))\n",
    "\n",
    "    power = (x - mus)/sigmas\n",
    "    power = power**2\n",
    "    assert power.shape == (n_seeds, xs, n_gmm, *xd)\n",
    "    power = torch.sum(power, dim=-1)\n",
    "    assert power.shape == (n_seeds, xs, n_gmm)\n",
    "    weights = weights.reshape((1, 1, n_gmm))\n",
    "    y = weights*torch.exp(-0.5*power)\n",
    "    assert y.shape == (n_seeds, xs, n_gmm)\n",
    "    y = torch.sum(y, dim=-1)\n",
    "    assert y.shape == (n_seeds, xs)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_rng = 12345\n",
    "torch.manual_seed(seed_rng)\n",
    "np.random.seed(seed_rng)\n",
    "\n",
    "data_type = \"gmm\"\n",
    "ds_name = data_type\n",
    "savedir = f\"../sample_trainset/{ds_name}\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "mu_2nds = [4, 6, 8, 10, 12] #list(np.arange(5, 51, 10))\n",
    "ros = [0.05, 0.1, 0.2, 0.4, 0.8, 1.]\n",
    "cfg_lists = [mu_2nds, ros]\n",
    "cfgs = itertools.product(*cfg_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bfe60",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "orc_specs = defaultdict(list)\n",
    "for cfg_it, cfg in enumerate(cfgs):\n",
    "    mu_2nd, ro = cfg\n",
    "    print(f\"cfg is {cfg}\")\n",
    "\n",
    "    # visualize the oracle\n",
    "    mu_1st = 0\n",
    "    mu_shift = 0\n",
    "\n",
    "    xd = 1\n",
    "    n_gmm = 2\n",
    "    mu_2nd = mu_2nd + mu_shift\n",
    "    mu_1st = mu_1st + mu_shift\n",
    "    \n",
    "    sigmas_gmm = torch.tensor([.25, 1.])\n",
    "    weights = torch.tensor([1., 2.5])\n",
    "\n",
    "    mus_gmm = [mu_1st*torch.ones(1, xd), mu_2nd*torch.ones(1, xd)]\n",
    "    mus = torch.cat(mus_gmm, dim=0)\n",
    "    assert mus.shape == (n_gmm, xd)\n",
    "    sigmas = sigmas_gmm.reshape(-1, 1).broadcast_to(n_gmm, xd)\n",
    "    \n",
    "    # define a distribution to sample x from\n",
    "    # take samples from the left gaussian\n",
    "    N1 = 200\n",
    "    mu1_sample = mu_1st\n",
    "    sigma1_sample = .6\n",
    "    x1_samples = mu1_sample + sigma1_sample*torch.randn((N1, 1))\n",
    "\n",
    "    # take samples from the right gaussian\n",
    "    N2 = int(N1*ro)\n",
    "    start = sigmas_gmm[-1]/2\n",
    "    end = sigmas_gmm[-1]\n",
    "    while True:\n",
    "        # make sure that the max y from the second gaussian\n",
    "        # is above the max of the first gaussian\n",
    "        x2_samples_shift = start + (end - start)*torch.rand((N2, 1))\n",
    "        x2_samples = mu_2nd + x2_samples_shift\n",
    "        x2_tmp = torch.unsqueeze(x2_samples, dim=0)\n",
    "        y2_tmp = oracle_gmm(x2_tmp, mus=mus, sigmas=sigmas, weights=weights)\n",
    "        ymax = torch.max(y2_tmp)\n",
    "        if (ymax > mu_1st):\n",
    "            break\n",
    "\n",
    "    X = torch.cat((x2_samples, x1_samples))\n",
    "    X = torch.unsqueeze(X, dim=0)\n",
    "    N = X.numel()\n",
    "\n",
    "    Y_mean = oracle_gmm(X, mus=mus, sigmas=sigmas, weights=weights).reshape(-1, 1) # (N,1)\n",
    "    #print(f\"max of y is {torch.max(Y_mean):.2f}\")\n",
    "\n",
    "    x = X.detach().numpy().reshape(-1, 1)\n",
    "    y = Y_mean.detach().numpy().reshape(-1)\n",
    "    sigmas_gmm = sigmas_gmm.detach().numpy()\n",
    "    weights = weights.detach().numpy()\n",
    "\n",
    "    orc_spec = dict(cfg_it=cfg_it, mu_1st=mu_1st, mu_2nd=mu_2nd, mu_shift=mu_shift,\n",
    "                    ro=ro, data_type=data_type, xd=xd, n_gmm=n_gmm,\n",
    "                    sigmas_gmm=sigmas_gmm, weights=weights, N1=N1, N=N1+N2)\n",
    "    np.savez(f\"{savedir}/ds{cfg_it}\", x=x, y=y, orc_spec=orc_spec)\n",
    "    \n",
    "    # to get all confings in one file\n",
    "    orc_specs[\"cfg_it\"].append(cfg_it)\n",
    "    orc_specs[\"mu_1st\"].append(mu_1st)\n",
    "    orc_specs[\"mu_2nd\"].append(mu_2nd)\n",
    "    orc_specs[\"mu_shift\"].append(mu_shift)\n",
    "    orc_specs[\"ro\"].append(ro)\n",
    "    orc_specs[\"data_type\"].append(data_type)\n",
    "    orc_specs[\"xd\"].append(xd)\n",
    "    orc_specs[\"n_gmm\"].append(n_gmm)\n",
    "    orc_specs[\"sigmas_gmm\"].append(sigmas_gmm)\n",
    "    orc_specs[\"weights\"].append(weights)\n",
    "    orc_specs[\"N1\"].append(N1)\n",
    "    orc_specs[\"N\"].append(N1+N2)\n",
    "    \n",
    "    cfg_all = pd.DataFrame.from_dict(orc_specs, orient='index').transpose()\n",
    "    cfg_all.columns = [\"cfg_it\", \"mu_1st\", \"mu_2nd\", \"mu_shift\", \"ro\", \"data_type\", \n",
    "                       \"xd\", \"n_gmm\", \"sigmas_gmm\", \"weights\", \"N1\", \"N\"]\n",
    "    cfg_all.to_csv(f\"{savedir}/cfgs\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170f9b4",
   "metadata": {},
   "source": [
    "### PINN Poisson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e7d13",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "seed_rng = 12345\n",
    "np.random.seed(seed_rng)\n",
    "\n",
    "data_type = \"pinn\"\n",
    "ds_name = data_type\n",
    "savedir = f\"../sample_trainset/{ds_name}\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "high_perc_ranges = [(30, 40), (40, 50), (50, 60), (60, 70), (70, 80)]\n",
    "ros = [0.05, 0.1, 0.2, 0.4, 0.8]\n",
    "cfg_lists = [high_perc_ranges, ros]\n",
    "cfgs = itertools.product(*cfg_lists)\n",
    "\n",
    "orc_specs = defaultdict(list)\n",
    "for cfg_it, cfg in enumerate(cfgs):\n",
    "    high_perc_range, ro = cfg\n",
    "    low_perc = 15\n",
    "    print(f\"cfg is {cfg}\")\n",
    "\n",
    "    data = np.load(\"../datasets/pinn_poisson.npz\")\n",
    "    x = data['x']\n",
    "    modeld, sold = x.shape # models by solutions\n",
    "    xbar = np.mean(x, axis=-1).reshape((modeld, 1))\n",
    "    x = x - xbar\n",
    "    assert x.shape == (modeld, sold)\n",
    "    \n",
    "    orc = data[\"gt\"]\n",
    "    dsr = int(sold**0.5)\n",
    "    orc_re = orc[0].reshape(dsr, dsr)\n",
    "    w_re = -orc_re\n",
    "    w_re = w_re - w_re.min()\n",
    "    w_re = w_re**2\n",
    "    w_re = w_re/w_re.sum()\n",
    "    \n",
    "#     plt.pcolormesh(w_re, cmap=\"RdBu\")\n",
    "#     plt.colorbar()\n",
    "\n",
    "    seed = data[\"rng_seed\"]\n",
    "    seed_unq = np.unique(seed)\n",
    "\n",
    "    orc = data[\"gt\"]\n",
    "    orc = orc - np.mean(orc, axis=-1).reshape((modeld,1))\n",
    "    epochs = data[\"epoch\"]\n",
    "\n",
    "    w = w_re.reshape(1, sold)\n",
    "    y_mse_w = np.sum(np.square(x - orc) * w, axis=-1)\n",
    "    y_mae = np.abs(x - orc).max(axis=-1) # max or mean\n",
    "    y = y_mse_w # this metric distinguishes the quality of solutions\n",
    "    \n",
    "    mylog= -np.log10(y)\n",
    "    thr1 = np.percentile(mylog, low_perc)\n",
    "    \n",
    "    low_end, high_end = high_perc_range\n",
    "    thr2 = np.percentile(mylog, low_end)\n",
    "    thr3 = np.percentile(mylog, high_end)\n",
    "\n",
    "    train_size = 1000\n",
    "    perc = 1 - ro\n",
    "    train_size1 = int(train_size*perc)\n",
    "    train_size2 = train_size - train_size1\n",
    "\n",
    "    idx = np.where(mylog <= thr1)[0]\n",
    "    rand_idx1 = np.random.choice(idx, size=train_size1, replace=False)\n",
    "\n",
    "    idx = np.where((mylog >= thr2) & (mylog <= thr3))[0]\n",
    "    rand_idx2 = np.random.choice(idx, size=train_size2, replace=False)\n",
    "    \n",
    "    rand_idx_comb = np.concatenate((rand_idx1, rand_idx2))\n",
    "    x_tr = x[rand_idx_comb, :]\n",
    "    y_tr = mylog[rand_idx_comb]\n",
    "    \n",
    "    orc_spec = dict(cfg_it=cfg_it, ro=ro, high_perc_range=high_perc_range,\n",
    "                    data_type=data_type, N=train_size, low_perc=low_perc)\n",
    "\n",
    "    #print(f\"max -log mse \", np.max(y_tr))\n",
    "    np.savez(f\"{savedir}/ds{cfg_it}\", x=x_tr, y=y_tr, orc_spec=orc_spec)\n",
    "    \n",
    "    # to get all confings in one file\n",
    "    orc_specs[\"cfg_it\"].append(cfg_it)\n",
    "    orc_specs[\"ro\"].append(ro)\n",
    "    orc_specs[\"high_perc_range\"].append(high_perc_range)\n",
    "    orc_specs[\"data_type\"].append(data_type)\n",
    "    orc_specs[\"low_perc\"].append(low_perc)\n",
    "    orc_specs[\"N\"].append(train_size)\n",
    "    \n",
    "    cfg_all = pd.DataFrame.from_dict(orc_specs, orient='index').transpose()\n",
    "    cfg_all.columns = [\"cfg_it\", \"ro\", \"high_perc_range\", \"data_type\", \"low_perc\", \"N\"]\n",
    "    cfg_all.to_csv(f\"{savedir}/cfgs\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opence172",
   "language": "python",
   "name": "opence172"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
